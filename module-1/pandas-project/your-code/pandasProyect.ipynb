{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importanción de pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lectura del e importación del csv como DataFrame\n",
    "df = pd.read_csv(\"./input/GSAF5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voy a renombrar columnas para facilitar el acceso\n",
    "df.columns =['caseNumber', 'date', 'year', 'type', 'country', 'area', 'location',\n",
    "       'activity', 'name', 'sex', 'age', 'injury', 'fatal(Y/N)', 'time',\n",
    "       'species', 'investigatorSource', 'pdf', 'hrefFormula', 'href',\n",
    "       'caseNumber1', 'caseNumber2', 'originalOrder', 'Unnamed22',\n",
    "       'Unnamed23']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compruebo columnas con valores nulos\n",
    "null_cols = df.isnull().sum()\n",
    "null_cols[null_cols > 0]\n",
    "null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo un data Frame con las columnas que no tienen valores nulos, están limpias\n",
    "dfNotNull = df[[\"caseNumber\",\"date\",\"year\",\"type\",\"pdf\",\"caseNumber1\",\"caseNumber2\",\"originalOrder\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''En este punto tomo la decisión de dropear del Data Frame principal las columnas Unnamed22 y 23,\n",
    "pues la totalidad de sus registros prácticamente son nulos'''\n",
    "df = df.drop(columns = [\"Unnamed22\",\"Unnamed23\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''la siguiente columnas con bastantes nulos es edad, esta vez lo que voy a hacer es meter en el dfNotNull una columna\n",
    " que se llame age(-1NoData) con los valores validos mas -1 para los valores inválidos'''\n",
    "dfNotNull[\"age(-1NoData)\"] = df['age'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''La siguiente columna con muchos nulos, más de la mitad es time, voy a hacer un display para decidir si me interesa\n",
    "guardar esa info'''\n",
    "\n",
    "pd.DataFrame(df['time'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Voy a cambiar los nulos, merece la pena limpiar la columna'''\n",
    "dfNotNull[\"timeDirty\"] = df['time'].fillna(\"noData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Voy a analizar species'''\n",
    "pd.DataFrame(df[\"species\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Decido cambiar los nulos a Shark involvement not confirmed, parece lógico agrupar en esta categoría los nulos'''\n",
    "dfNotNull[\"species\"] = df['species'].fillna(\"Shark involvement not confirmed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''el resto de columnas que tienen no válidos contienen pocos por lo que voy a meter valores que no lleven a confusión'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNotNull[\"country\"] = df['country'].fillna(\"unknown\")\n",
    "dfNotNull[\"area\"] = df['area'].fillna(\"unknown\")\n",
    "dfNotNull[\"location\"] = df['location'].fillna(\"unknown\")\n",
    "dfNotNull[\"activity\"] = df['activity'].fillna(\"unknown\")\n",
    "dfNotNull[\"name\"] = df['name'].fillna(\"unknown\")\n",
    "dfNotNull[\"sex\"] = df['sex'].fillna(\"unknown\")\n",
    "dfNotNull[\"injury\"] = df['injury'].fillna(\"unknown\")\n",
    "dfNotNull[\"fatal(Y/N/unknow)\"] = df['fatal(Y/N)'].fillna(\"unknown\")\n",
    "dfNotNull[\"investigatorSource\"] = df['investigatorSource'].fillna(\"unknown\")\n",
    "dfNotNull[\"hrefFormula\"] = df['hrefFormula'].fillna(\"unknown\")\n",
    "dfNotNull[\"href\"] = df['href'].fillna(\"unknown\")\n",
    "#Compruebo que no hay nulos\n",
    "null_cols = dfNotNull.isnull().sum()\n",
    "#null_cols[null_cols > 0]\n",
    "null_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de \"fatal\"\n",
    "fatal = \"fatal(Y/N/unknow)\"\n",
    "cleanFatal = dfNotNull[fatal]\n",
    "cleanFatal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import cleanTextInFatal\n",
    "cleanFatal = cleanFatal.apply(cleanTextInFatal)\n",
    "cleanFatal.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo añado a un dataFrame que tendrá los datos limpios\n",
    "dfClean = pd.DataFrame(cleanFatal)\n",
    "dfNotNull = dfNotNull.drop(columns =fatal)\n",
    "#elimino los objetos que no voy a usar\n",
    "del cleanFatal\n",
    "del fatal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNotNull.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voy a analizar type\n",
    "dfNotNull[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diría que no tiene demasiado sentido Sea disaster, boat y boating, los voy a cambiar a junto con Ivalid a unknown\n",
    "dfClean[\"type\"]=dfNotNull[\"type\"].replace(\n",
    "    ['Invalid', 'Sea Disaster',\"Boat\",\"Boating\"],\n",
    "    'UNKNOWN',\n",
    "    \n",
    ")\n",
    "dfNotNull=dfNotNull.drop(columns = \"type\")\n",
    "dfClean[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNotNull.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso a activity\n",
    "activitySerie = dfNotNull[\"activity\"]\n",
    "activitySerie.value_counts().head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Voy a hacer alguno replace para unificar algunos datos fáciles\"\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Swimming ',\"Floating on his back\"],\n",
    "    'Swimming',\n",
    "    \n",
    ")\n",
    "activitySerie=activitySerie.replace(\n",
    "    'Fishing ',\n",
    "    'Fishing',\n",
    "    \n",
    ")\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Diving for abalone',\"Diving for trochus\",\"Fishing for mackerel\",\"Free diving for abalone\",\"Sponge diving\",\n",
    "    \"Hard hat diving\", \"Diving for coins\",\"Freediving\"\n",
    "],\n",
    "\"Diving\"    \n",
    ")\n",
    "\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Surfing (sitting on his board)',\"Sitting on surfboard\"],\n",
    "\"Surfing\"   \n",
    ")\n",
    "\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Treading water',\"Playing\",\"Walking\",\"Standing\"],\n",
    "\"Wading\"  \n",
    ")\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Spearfishing ',\"Skindiving\",\"Spearfishing on Scuba\",\"Scuba diving (but on surface)\",\"Scuba diving (submerged)\"],\n",
    "\"Spearfishing\"   \n",
    ")\n",
    "activitySerie=activitySerie.replace(\n",
    "    [\"Murder\",\"Sea Disaster\"],\n",
    "\"unknown\"  \n",
    ")\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Fell overboard ',\"Canoeing\",\"Fell into the water\",\"Boat\",\"Dangling feet in the water\",\"Sailing \"],\n",
    "\"Boating\"   \n",
    ")\n",
    "\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Surf-skiing  ',\"Surf skiing \"],\n",
    "\"Surf skiing\"   \n",
    ")\n",
    "\n",
    "activitySerie=activitySerie.replace(\n",
    "    ['Sea Disaster '],\n",
    "\"Sea Disaster\"   \n",
    ")\n",
    " \n",
    "activitySerie.value_counts().head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voy a categorizar la columna en los grupos que actualmente tienen más de 6 registros, \n",
    "#para ello hago una lista con los que tienen menos de 11 para ir filtrando y ver en qué categoria los meto \n",
    "\n",
    "badGroupsInActivity =pd.DataFrame(activitySerie.value_counts()).query(\"activity<11\").index\n",
    "\n",
    "badGroupsInActivity = [str(ele) for ele in badGroupsInActivity]\n",
    "print(len(badGroupsInActivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programé unas funciones para que me formatearan en las categorías la columna\n",
    "from functions import cleanActivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activitySerie = activitySerie.apply(cleanActivity,lista = badGroupsInActivity)\n",
    "\n",
    "activitySerie.value_counts().head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Vuelvo a hacer print de la lista de valores que no quiero por si me hubiera dejado algo\"\n",
    "badGroupsInActivity =pd.DataFrame(activitySerie.value_counts()).query(\"activity<11\").index\n",
    "\n",
    "badGroupsInActivity = [str(ele) for ele in badGroupsInActivity]\n",
    "print(len(badGroupsInActivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perfecto, aún veo un par de índices que puedo categorizar, puedo usar la misma función para ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaConCategoriasFusionables =[\"Surf-skiing\",\"Boating\",\"Fishing for sharks\"]\n",
    "listaConCategoriasFusionables = [str(ele) for ele in listaConCategoriasFusionables]\n",
    "activitySerie=activitySerie.replace(\n",
    "    \"Surf-skiing\",\n",
    "\"Surf skiing\"  \n",
    ")\n",
    "activitySerie=activitySerie.replace(\n",
    "    [\"Rowing\",\"Boating\"],\n",
    "\"Sailing\"  \n",
    ")\n",
    "activitySerie=activitySerie.replace(\n",
    "    'Fishing for sharks',\n",
    "\"Shark fishing\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(activitySerie.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En este punto creo que activity está muy limpio, lo añado y borro variables que no vaya a usar\n",
    "dfClean[\"activity\"] = activitySerie\n",
    "del activitySerie\n",
    "del badGroupsInActivity\n",
    "dfNotNull = dfNotNull.drop(columns = \"activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voy a ver si href y hrefFormula es información duplicada\n",
    "import numpy as np\n",
    "array = (dfNotNull[\"href\"].values == dfNotNull[\"hrefFormula\"].values)\n",
    "array.size - np.sum(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programé una función para comprobar si la url que se le pasa es válida y el archivo exite, si lo es devuelve la Url, si no Unknown\n",
    "from functions import checkUrlValid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok ya tengo las válidas de href, ahora solo voy a pasar la función en href formula para los índice unknown por si puedo salvar alguna\n",
    "\"\"\"validHref = dfNotNull[\"href\"].apply(checkUrlValid)\n",
    "validHref\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"voy a guardar el df en un csv, porque la función es lenta, creo que la razón es que el servidor\n",
    "solo deja hacer unas pocas peticiones por unidad de tiempo\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"validHref = validHref.astype(str)\n",
    "pd.DataFrame(validHref).to_csv(\"./validHrefDf.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compruebo que se guardó, href válidas a 1-09-2019 01:11 AM\n",
    "validHref = pd.read_csv(\"./outputignore/validHrefDf.csv\")\n",
    "validHref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voy a ver las que no sirven\n",
    "validHref[\"href\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo hay 4 que no sirven asique creo que es bastante coherente añadir esta lista como limpia, y teniendo encuenta que solo 54 no coinciden con href formula creo que ésta última se puede dropear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClean[\"href(verified1-09-2019)\"] = validHref[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNotNull[\"country\"].value_counts().head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pienso que country está bastande limpio así que lo voy a añadir tal cual\n",
    "dfClean[\"country\"] = dfNotNull[\"country\"]\n",
    "dfNotNull=dfNotNull.drop(columns=\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voy a analizar la columna de sex, parece facil\n",
    "dfNotNull[\"sex\"].value_counts().index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNotNull[\"sex\"] = dfNotNull[\"sex\"].replace([\"M \"],\"M\")\n",
    "dfNotNull[\"sex\"] = dfNotNull[\"sex\"].replace([\".\",\"lli\",\"N\"],\"unknown\")\n",
    "dfClean[\"sex\"]= dfNotNull[\"sex\"]\n",
    "dfNotNull =dfNotNull.drop(columns = \"sex\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClean[\"sex\"].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfNotNull[\"species\"].value_counts().head(40)\n",
    "##Observo que en esta columna hay bastantes datos de longitud por lo que los voy a intentar separar y colocar en una columna de longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import getLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDirtyLenght = pd.DataFrame(dfNotNull[\"species\"].astype(\"str\").apply(getLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora renombrando la columna ya  tengo un dataframe con datos de longitudes\n",
    "dfDirtyLenght.columns = [\"lenght\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDirtyLenght[\"lenght\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dejo para después las longitudes, voy a limpiar las especies ahora que puedo prescindir de las longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dfNotNull[\"species\"].value_counts()).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, voy a identificar una lista de especies y para pasarla como parámetro a mi función de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listSpecies =['WHITE','TIGUER','BULL','WOBBEGONG','BLACKSTRIP','MAKO','BLUE','RAGGEDTOOTH','ZAMBESI','BRONZE WHALER','OCEANIC','SPINNER','HAMMERHEAD','BLACKTIP','SALMON','DUSKY','REEF','LEOPARD','LEMON','SEVENGILL','BLACKTIP','DOGFISH','SEVENGILL','THRESHER','GALAPAGOS',\"NURSE\"]\n",
    "from functions import cleanShark\n",
    "dfClean[\"species\"]=dfNotNull[\"species\"].apply(cleanShark,speciesList = listSpecies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClean[\"species\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, mi columna de species está limpia, la dropeo de dfNotNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNotNull = dfNotNull.drop(columns = \"species\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = \"href(verified1-09-2019)\"\n",
    "dfClean[href].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkUrlValid(text):\n",
    "    \"\"\"analiza si un string contiene una url válida (404 no valida) y la devuelve si lo es, si no devuelve UNKNOWN\"\"\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        r = requests.get(text, allow_redirects=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "     \n",
    "    \n",
    "        return r.headers\n",
    "    except:\n",
    "            return \"EXCEP\" \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = checkUrlValid(\"http://sharkattackfile.net/spreadsheets/pdf_directory/2016.09.18.a-NS.pdf\")\n",
    "checkUrlValid(\"http://sharkattackfile.net/spreadsheets/pdf_directory/2014.12.23.R-Goblk.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"http://sharkattackfile.net/spreadsheets/pdf_directory/2014.12.23.R-Goblk.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validHref[\"href\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
